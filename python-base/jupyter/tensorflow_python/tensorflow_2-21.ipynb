{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# python3.5 environment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Tensor.eval of <tf.Tensor 'MatMul:0' shape=(1, 1) dtype=float32>>\n",
      "<tf.Variable 'Variable_1:0' shape=(2, 1) dtype=float32_ref>\n",
      "Tensor(\"MatMul:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 初始化环境变量\n",
    "w=tf.Variable([[0.5,1.0]])\n",
    "x=tf.Variable([[2.0],[3.0]])\n",
    "y=tf.matmul(w,x)\n",
    "\n",
    "init_op=tf.global_variables_initializer()\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    print(y.eval)\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'range:0' shape=(5,) dtype=int32>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 构建数字对象\n",
    "\n",
    "tensor=tf.constant([1,2,3,4,5,6,7,]) # [1,2,3,4,5,6,7]\n",
    "tensor=tf.constant(-1.0,shape=[2,3]) # [[-1.,-1.,-1.],[-1.,-1.,-1.]]\n",
    "tf.linspace(10.0,12.0,3,name=\"linspace\") # [ 10.0 11.0 12.0]\n",
    "start=3\n",
    "limit=18\n",
    "delta=3\n",
    "tf.range(start,limit,delta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.92884898  0.72279453 -0.84405452]\n",
      " [-3.22858214  2.7976141   2.51509047]]\n",
      "[[1 2]\n",
      " [5 6]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "# 随机数\n",
    "nrm=tf.random_normal([2,3],mean=-1,stddev=4)\n",
    "\n",
    "c=tf.constant([[1,2],[3,4],[5,6]])\n",
    "shuff=tf.random_shuffle(c)\n",
    "sess=tf.Session()\n",
    "print(sess.run(nrm))\n",
    "print(sess.run(shuff))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "arr=np.zeros((3,3))\n",
    "tarr=tf.convert_to_tensor(arr)\n",
    "with tf.Session() as sess:\n",
    "    print(sess.run(tarr))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17bdd9f6048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 随机生成1000 个点，围绕在 y=0.1x+0.3的直线周围，生成样本数据\n",
    "num_points=1000\n",
    "vectors_set=[]\n",
    "for i in range(num_points):\n",
    "    x=np.random.normal(0.0,0.55)\n",
    "    y=x*0.1+0.3+np.random.normal(0.0,0.03)\n",
    "    vectors_set.append([x,y])\n",
    "# 生成一些样本\n",
    "x_data=[v[0] for v in vectors_set]\n",
    "y_data=[v[1] for v in vectors_set]\n",
    "plt.scatter(x_data,y_data,c='r')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w= [-0.31118155] b= [ 0.] loss= 0.132966\n",
      "w= [-0.19932316] b= [ 0.2873455] loss= 0.0270585\n",
      "w= [-0.11157345] b= [ 0.29086849] loss= 0.0139092\n",
      "w= [-0.04972485] b= [ 0.29363221] loss= 0.00737422\n",
      "w= [-0.0061233] b= [ 0.29558018] loss= 0.00412644\n",
      "w= [ 0.02461459] b= [ 0.29695341] loss= 0.00251234\n",
      "w= [ 0.04628393] b= [ 0.29792151] loss= 0.00171015\n",
      "w= [ 0.06156022] b= [ 0.29860401] loss= 0.00131148\n",
      "w= [ 0.07232958] b= [ 0.29908514] loss= 0.00111334\n",
      "w= [ 0.07992168] b= [ 0.29942432] loss= 0.00101487\n",
      "w= [ 0.08527389] b= [ 0.29966345] loss= 0.000965933\n",
      "w= [ 0.08904706] b= [ 0.29983202] loss= 0.000941611\n",
      "w= [ 0.09170704] b= [ 0.29995084] loss= 0.000929524\n",
      "w= [ 0.09358224] b= [ 0.30003461] loss= 0.000923516\n",
      "w= [ 0.09490421] b= [ 0.30009368] loss= 0.000920531\n",
      "w= [ 0.09583616] b= [ 0.30013531] loss= 0.000919047\n",
      "w= [ 0.09649316] b= [ 0.30016467] loss= 0.00091831\n",
      "w= [ 0.09695633] b= [ 0.30018535] loss= 0.000917943\n",
      "w= [ 0.09728285] b= [ 0.30019996] loss= 0.000917761\n",
      "w= [ 0.09751303] b= [ 0.30021024] loss= 0.00091767\n",
      "w= [ 0.09767531] b= [ 0.30021748] loss= 0.000917625\n",
      "w= [ 0.09778971] b= [ 0.30022261] loss= 0.000917603\n",
      "w= [ 0.09787036] b= [ 0.30022621] loss= 0.000917592\n",
      "w= [ 0.09792722] b= [ 0.30022874] loss= 0.000917586\n",
      "w= [ 0.0979673] b= [ 0.30023053] loss= 0.000917584\n",
      "w= [ 0.09799556] b= [ 0.30023178] loss= 0.000917582\n",
      "w= [ 0.09801547] b= [ 0.30023268] loss= 0.000917582\n",
      "w= [ 0.09802952] b= [ 0.3002333] loss= 0.000917581\n",
      "w= [ 0.09803942] b= [ 0.30023375] loss= 0.000917581\n",
      "w= [ 0.0980464] b= [ 0.30023408] loss= 0.000917581\n",
      "w= [ 0.09805132] b= [ 0.30023429] loss= 0.000917581\n",
      "w= [ 0.09805479] b= [ 0.30023444] loss= 0.000917581\n",
      "w= [ 0.09805723] b= [ 0.30023456] loss= 0.000917581\n",
      "w= [ 0.09805895] b= [ 0.30023462] loss= 0.000917581\n",
      "w= [ 0.09806017] b= [ 0.30023468] loss= 0.000917581\n",
      "w= [ 0.09806103] b= [ 0.30023471] loss= 0.000917581\n",
      "w= [ 0.09806163] b= [ 0.30023474] loss= 0.000917581\n",
      "w= [ 0.09806205] b= [ 0.30023476] loss= 0.000917581\n",
      "w= [ 0.09806235] b= [ 0.30023476] loss= 0.000917581\n",
      "w= [ 0.09806257] b= [ 0.30023479] loss= 0.000917581\n",
      "w= [ 0.09806272] b= [ 0.30023479] loss= 0.000917581\n",
      "w= [ 0.09806282] b= [ 0.30023479] loss= 0.000917581\n",
      "w= [ 0.0980629] b= [ 0.30023479] loss= 0.000917581\n",
      "w= [ 0.09806295] b= [ 0.30023479] loss= 0.000917581\n",
      "w= [ 0.09806298] b= [ 0.30023479] loss= 0.000917581\n",
      "w= [ 0.09806301] b= [ 0.30023479] loss= 0.000917581\n",
      "w= [ 0.09806303] b= [ 0.30023479] loss= 0.000917581\n",
      "w= [ 0.09806304] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806305] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806306] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n",
      "w= [ 0.09806307] b= [ 0.30023482] loss= 0.000917581\n"
     ]
    }
   ],
   "source": [
    "# 通过\n",
    "# 生成1维的w矩阵，取值是 [-1,1]之间的随机数\n",
    "w=tf.Variable(tf.random_uniform([1],-1.0,1.0),name='W')\n",
    "# 生成1维的b矩阵，初始值是0\n",
    "b=tf.Variable(tf.zeros([1],name='b'))\n",
    "# 经过计算得出预估值 y\n",
    "y=w*x_data+b\n",
    "# 以估计值 y和实际值 y_data之间的均方差作为损失\n",
    "loss =tf.reduce_mean(tf.square(y-y_data),name='loss')\n",
    "# 采用梯度下降法来优化参数\n",
    "optimizer=tf.train.GradientDescentOptimizer(0.5)\n",
    "# 训练的过程就是最小化这个误差值\n",
    "train=optimizer.minimize(loss,name='train')\n",
    "\n",
    "sess=tf.Session()\n",
    "init=tf.global_variables_initializer()\n",
    "sess.run(init)\n",
    "print('w=',sess.run(w),'b=',sess.run(b),'loss=',sess.run(loss))\n",
    "# 执行20次训练\n",
    "for step in range(200):\n",
    "    sess.run(train)\n",
    "    # 输出训练好的 w和b\n",
    "    print('w=',sess.run(w),'b=',sess.run(b),'loss=',sess.run(loss))\n",
    "writer=tf.train.SummarySaverHook(sess.graph,scaffold=tf.train.Scaffold(summary_op=tf.summary.merge_all()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
